{
    "learning_rate": 1e-3,
    "batch_size": 5,
    "num_epochs": 100,

    "model_type": "hoveyma",
    "embed_types": ["word"],
    "bert_type": "bert-base-cased",

    "lstm_hidden_size": 200,
    "word_embedding_size": 200,
    "char_embedding_size": 50,
    "dropout_rate": 0.5,
    "cnn_num_filters": 30,
    "cnn_window_size": 3,


    "save_summary_steps": 100
}
