2019-03-18 09:32:15,014:INFO: Loading the datasets...
2019-03-18 09:32:15,215:INFO: loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/msingh9/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2019-03-18 09:32:15,659:INFO: - done.
2019-03-18 09:32:15,695:INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at /home/msingh9/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c
2019-03-18 09:32:15,696:INFO: extracting archive file /home/msingh9/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmpahf7sjke
2019-03-18 09:32:19,285:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

2019-03-18 09:32:26,313:INFO: learning_rate => 2e-05
2019-03-18 09:32:26,314:INFO: batch_size => 8
2019-03-18 09:32:26,314:INFO: defm_dropout_rate => 0.5
2019-03-18 09:32:26,314:INFO: Starting training for 10 epoch(s)
2019-03-18 09:32:26,314:INFO: Epoch 1/10
2019-03-18 10:10:41,035:INFO: - Train metrics: fn: 0.880 ; loss: 0.379 ; fp: 0.181 ; tp: 0.096 ; accuracy: 0.867
2019-03-18 10:12:17,872:INFO: - Eval metrics : accuracy: 0.897 ; f1score: 0.385 ; loss: 0.331 ; precision: 0.717 ; recall: 0.263
2019-03-18 10:12:20,147:INFO: - Found new best accuracy
2019-03-18 10:12:20,147:INFO: Epoch 2/10
2019-03-18 10:50:27,651:INFO: - Train metrics: fn: 0.880 ; loss: 0.360 ; fp: 0.145 ; tp: 0.096 ; accuracy: 0.872
2019-03-18 10:52:04,655:INFO: - Eval metrics : accuracy: 0.878 ; f1score: 0.000 ; loss: 0.370 ; precision: 0.000 ; recall: 0.000
2019-03-18 10:52:19,884:INFO: Epoch 3/10
2019-03-18 11:30:26,597:INFO: - Train metrics: fn: 0.976 ; loss: 0.380 ; fp: 0.000 ; tp: 0.000 ; accuracy: 0.878
2019-03-18 11:32:03,780:INFO: - Eval metrics : accuracy: 0.878 ; f1score: 0.000 ; loss: 0.377 ; precision: 0.000 ; recall: 0.000
2019-03-18 11:32:18,919:INFO: Epoch 4/10
2019-03-18 12:10:25,631:INFO: - Train metrics: fn: 0.976 ; loss: 0.373 ; fp: 0.000 ; tp: 0.000 ; accuracy: 0.878
2019-03-18 12:12:02,710:INFO: - Eval metrics : accuracy: 0.878 ; f1score: 0.000 ; loss: 0.375 ; precision: 0.000 ; recall: 0.000
2019-03-18 12:12:18,060:INFO: Epoch 5/10
2019-03-18 12:50:22,220:INFO: - Train metrics: fn: 0.976 ; loss: 0.379 ; fp: 0.000 ; tp: 0.000 ; accuracy: 0.878
2019-03-18 12:51:59,237:INFO: - Eval metrics : accuracy: 0.878 ; f1score: 0.000 ; loss: 0.377 ; precision: 0.000 ; recall: 0.000
2019-03-18 12:52:14,229:INFO: Epoch 6/10
2019-03-18 13:30:20,991:INFO: - Train metrics: fn: 0.976 ; loss: 0.376 ; fp: 0.000 ; tp: 0.000 ; accuracy: 0.878
2019-03-18 13:31:58,127:INFO: - Eval metrics : accuracy: 0.878 ; f1score: 0.000 ; loss: 0.381 ; precision: 0.000 ; recall: 0.000
2019-03-18 13:32:13,355:INFO: Epoch 7/10
2019-03-18 14:10:18,801:INFO: - Train metrics: fn: 0.976 ; loss: 0.378 ; fp: 0.000 ; tp: 0.000 ; accuracy: 0.878
2019-03-18 14:11:55,926:INFO: - Eval metrics : accuracy: 0.878 ; f1score: 0.000 ; loss: 0.382 ; precision: 0.000 ; recall: 0.000
2019-03-18 14:12:11,000:INFO: Epoch 8/10
2019-03-18 17:04:16,261:INFO: Loading the datasets...
2019-03-18 17:04:16,443:INFO: loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/msingh9/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2019-03-18 17:04:16,904:INFO: - done.
2019-03-18 17:04:16,935:INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at /home/msingh9/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c
2019-03-18 17:04:16,936:INFO: extracting archive file /home/msingh9/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmpq4xkpond
2019-03-18 17:04:20,494:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

2019-03-18 17:04:27,428:INFO: learning_rate => 1e-06
2019-03-18 17:04:27,428:INFO: batch_size => 8
2019-03-18 17:04:27,428:INFO: defm_dropout_rate => 0.5
2019-03-18 17:04:27,429:INFO: Starting training for 10 epoch(s)
2019-03-18 17:04:27,429:INFO: Epoch 1/10
2019-03-18 17:42:54,310:INFO: - Train metrics: fp: 0.241 ; tp: 0.325 ; accuracy: 0.889 ; fn: 0.651 ; loss: 0.319
2019-03-18 17:44:31,447:INFO: - Eval metrics : accuracy: 0.913 ; f1score: 0.605 ; loss: 0.238 ; precision: 0.682 ; recall: 0.544
2019-03-18 17:45:07,936:INFO: - Found new best accuracy
2019-03-18 17:45:07,937:INFO: Epoch 2/10
2019-03-18 18:23:33,303:INFO: - Train metrics: fp: 0.229 ; tp: 0.470 ; accuracy: 0.908 ; fn: 0.506 ; loss: 0.257
2019-03-18 18:25:10,688:INFO: - Eval metrics : accuracy: 0.915 ; f1score: 0.616 ; loss: 0.235 ; precision: 0.692 ; recall: 0.556
2019-03-18 18:25:46,948:INFO: - Found new best accuracy
2019-03-18 18:25:46,949:INFO: Epoch 3/10
2019-03-18 19:04:12,840:INFO: - Train metrics: fp: 0.205 ; tp: 0.518 ; accuracy: 0.917 ; fn: 0.458 ; loss: 0.240
2019-03-18 19:05:50,304:INFO: - Eval metrics : accuracy: 0.917 ; f1score: 0.630 ; loss: 0.244 ; precision: 0.698 ; recall: 0.574
2019-03-18 19:06:26,466:INFO: - Found new best accuracy
2019-03-18 19:06:26,467:INFO: Epoch 4/10
2019-03-18 19:44:55,355:INFO: - Train metrics: fp: 0.229 ; tp: 0.554 ; accuracy: 0.919 ; fn: 0.422 ; loss: 0.244
2019-03-18 19:46:32,926:INFO: - Eval metrics : accuracy: 0.918 ; f1score: 0.634 ; loss: 0.253 ; precision: 0.700 ; recall: 0.580
2019-03-18 19:47:09,092:INFO: - Found new best accuracy
2019-03-18 19:47:09,093:INFO: Epoch 5/10
2019-03-18 20:25:38,240:INFO: - Train metrics: fp: 0.241 ; tp: 0.554 ; accuracy: 0.917 ; fn: 0.422 ; loss: 0.234
2019-03-18 20:27:15,564:INFO: - Eval metrics : accuracy: 0.918 ; f1score: 0.639 ; loss: 0.256 ; precision: 0.691 ; recall: 0.594
2019-03-18 20:27:51,605:INFO: - Found new best accuracy
2019-03-18 20:27:51,605:INFO: Epoch 6/10
2019-03-18 21:06:21,821:INFO: - Train metrics: fp: 0.241 ; tp: 0.602 ; accuracy: 0.923 ; fn: 0.373 ; loss: 0.220
2019-03-18 21:07:59,469:INFO: - Eval metrics : accuracy: 0.918 ; f1score: 0.639 ; loss: 0.255 ; precision: 0.692 ; recall: 0.594
2019-03-18 21:08:35,489:INFO: - Found new best accuracy
2019-03-18 21:08:35,489:INFO: Epoch 7/10
2019-03-18 21:47:05,467:INFO: - Train metrics: fp: 0.229 ; tp: 0.590 ; accuracy: 0.923 ; fn: 0.386 ; loss: 0.222
2019-03-18 21:48:43,053:INFO: - Eval metrics : accuracy: 0.913 ; f1score: 0.645 ; loss: 0.254 ; precision: 0.644 ; recall: 0.647
2019-03-18 21:49:19,456:INFO: - Found new best accuracy
2019-03-18 21:49:19,457:INFO: Epoch 8/10
2019-03-18 22:27:50,840:INFO: - Train metrics: fp: 0.217 ; tp: 0.590 ; accuracy: 0.925 ; fn: 0.386 ; loss: 0.213
2019-03-18 22:29:28,388:INFO: - Eval metrics : accuracy: 0.918 ; f1score: 0.632 ; loss: 0.267 ; precision: 0.706 ; recall: 0.572
2019-03-18 22:29:43,386:INFO: Epoch 9/10
2019-03-18 23:08:13,474:INFO: - Train metrics: fp: 0.157 ; tp: 0.614 ; accuracy: 0.935 ; fn: 0.361 ; loss: 0.193
2019-03-18 23:09:50,972:INFO: - Eval metrics : accuracy: 0.916 ; f1score: 0.639 ; loss: 0.272 ; precision: 0.676 ; recall: 0.606
2019-03-18 23:10:06,146:INFO: Epoch 10/10
2019-03-18 23:48:37,998:INFO: - Train metrics: fp: 0.217 ; tp: 0.651 ; accuracy: 0.932 ; fn: 0.325 ; loss: 0.213
2019-03-18 23:50:15,639:INFO: - Eval metrics : accuracy: 0.916 ; f1score: 0.631 ; loss: 0.284 ; precision: 0.679 ; recall: 0.589
2019-03-19 00:01:14,440:INFO: Loading the datasets...
2019-03-19 00:01:14,685:INFO: loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/msingh9/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2019-03-19 00:01:15,136:INFO: - done.
2019-03-19 00:01:15,214:INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at /home/msingh9/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c
2019-03-19 00:01:15,214:INFO: extracting archive file /home/msingh9/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmpa0qgmpk2
2019-03-19 00:01:18,851:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

2019-03-19 00:01:25,938:INFO: learning_rate => 1e-07
2019-03-19 00:01:25,938:INFO: batch_size => 8
2019-03-19 00:01:25,938:INFO: defm_dropout_rate => 0.5
2019-03-19 00:01:25,938:INFO: Starting training for 10 epoch(s)
2019-03-19 00:01:25,938:INFO: Restoring parameters from experiments/bert/ours/base_model/best.pth.tar
2019-03-19 00:01:26,944:INFO: Epoch 1/10
2019-03-19 00:40:02,107:INFO: - Train metrics: accuracy: 0.934 ; fn: 0.349 ; fp: 0.181 ; loss: 0.206 ; tp: 0.627
2019-03-19 00:41:39,112:INFO: - Eval metrics : accuracy: 0.918 ; f1score: 0.639 ; loss: 0.269 ; precision: 0.692 ; recall: 0.593
2019-03-19 00:42:15,723:INFO: - Found new best accuracy
2019-03-19 00:42:15,723:INFO: Epoch 2/10
2019-03-19 01:20:46,025:INFO: - Train metrics: accuracy: 0.934 ; fn: 0.361 ; fp: 0.169 ; loss: 0.217 ; tp: 0.614
2019-03-19 01:22:23,362:INFO: - Eval metrics : accuracy: 0.916 ; f1score: 0.623 ; loss: 0.285 ; precision: 0.695 ; recall: 0.564
2019-03-19 01:22:38,601:INFO: Epoch 3/10
2019-03-19 02:01:07,242:INFO: - Train metrics: accuracy: 0.938 ; fn: 0.313 ; fp: 0.181 ; loss: 0.207 ; tp: 0.663
2019-03-19 02:02:44,556:INFO: - Eval metrics : accuracy: 0.914 ; f1score: 0.645 ; loss: 0.287 ; precision: 0.652 ; recall: 0.638
2019-03-19 02:03:20,564:INFO: - Found new best accuracy
2019-03-19 02:03:20,565:INFO: Epoch 4/10
2019-03-19 02:41:51,741:INFO: - Train metrics: accuracy: 0.940 ; fn: 0.325 ; fp: 0.157 ; loss: 0.190 ; tp: 0.651
2019-03-19 02:43:29,063:INFO: - Eval metrics : accuracy: 0.915 ; f1score: 0.649 ; loss: 0.290 ; precision: 0.658 ; recall: 0.641
2019-03-19 02:44:05,090:INFO: - Found new best accuracy
2019-03-19 02:44:05,090:INFO: Epoch 5/10
2019-03-19 03:22:33,399:INFO: - Train metrics: accuracy: 0.947 ; fn: 0.253 ; fp: 0.169 ; loss: 0.177 ; tp: 0.723
2019-03-19 03:24:10,664:INFO: - Eval metrics : accuracy: 0.916 ; f1score: 0.636 ; loss: 0.301 ; precision: 0.674 ; recall: 0.601
2019-03-19 03:24:25,684:INFO: Epoch 6/10
2019-03-19 04:02:54,896:INFO: - Train metrics: accuracy: 0.947 ; fn: 0.277 ; fp: 0.145 ; loss: 0.179 ; tp: 0.699
2019-03-19 04:04:32,316:INFO: - Eval metrics : accuracy: 0.916 ; f1score: 0.638 ; loss: 0.317 ; precision: 0.676 ; recall: 0.605
2019-03-19 04:04:47,417:INFO: Epoch 7/10
2019-03-19 04:43:16,720:INFO: - Train metrics: accuracy: 0.944 ; fn: 0.229 ; fp: 0.217 ; loss: 0.169 ; tp: 0.747
2019-03-19 04:44:54,235:INFO: - Eval metrics : accuracy: 0.909 ; f1score: 0.645 ; loss: 0.321 ; precision: 0.617 ; recall: 0.677
2019-03-19 04:45:09,496:INFO: Epoch 8/10
2019-03-19 05:23:40,133:INFO: - Train metrics: accuracy: 0.946 ; fn: 0.253 ; fp: 0.181 ; loss: 0.178 ; tp: 0.723
2019-03-19 05:25:17,418:INFO: - Eval metrics : accuracy: 0.916 ; f1score: 0.632 ; loss: 0.339 ; precision: 0.678 ; recall: 0.591
2019-03-19 05:25:32,763:INFO: Epoch 9/10
2019-03-19 06:04:02,549:INFO: - Train metrics: accuracy: 0.947 ; fn: 0.277 ; fp: 0.145 ; loss: 0.173 ; tp: 0.699
2019-03-19 06:05:39,855:INFO: - Eval metrics : accuracy: 0.912 ; f1score: 0.634 ; loss: 0.334 ; precision: 0.642 ; recall: 0.626
2019-03-19 06:05:54,887:INFO: Epoch 10/10
2019-03-19 06:44:25,306:INFO: - Train metrics: accuracy: 0.949 ; fn: 0.241 ; fp: 0.169 ; loss: 0.174 ; tp: 0.735
2019-03-19 06:46:02,594:INFO: - Eval metrics : accuracy: 0.914 ; f1score: 0.625 ; loss: 0.352 ; precision: 0.673 ; recall: 0.584
